{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled219.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbBk/xTFNsECKjHJY3Q6Ow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RojaCM/DEEP-LEARNING-/blob/main/NLP%20BASICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY_qlibee6oy",
        "outputId": "b66fa40f-0c63-4021-b50a-e177ad6955d8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize"
      ],
      "metadata": {
        "id": "674vSOS6fG7Z"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Paragraph : Information about Manav Project\n",
        "data=\"Recent times have witnessed an explosion in the amount of biological data generated. There are millions of research articles with pivotal information on human health and disease, spanning from single molecule resolution to the level of the whole organism. However, this information is scattered in different databases, repositories and in the text of journal articles. This makes the seamless extraction of scientific information an extremely challenging and time-consuming (yet incomplete) process. With 100+ databases and millions of data points (combined) from just human cells/tissue and disease, there is a pressing need to collate this information in such a way that users like academic/industrial/clinical researcher as well as teachers and students can easily access information that is relevant to them from a common and modular platform. Although there are ambitious ongoing efforts like the Recon X, The Virtual Physiological Human, Human Cell Atlas, none of these projects aim to build the map of the whole human body simultaneously comparing both macro(organ/tissue/cell) and micro (molecular interaction networks) level details. Manav-Human Atlas Initiative aims to construct a comprehensive map of the entire human body which will explicitly document macro to micro level information. The project Manav will dramatically accelerate our understanding of the working of the human body and help design better therapeutic targets for treating diseases like cancer, diabetes and more. This project will require understanding, extracting and collating information from millions of scientific papers which would need a massive investment of time, effort and manpower. The large pool of scientifically literate population in India pursuing a bachelors /masters / Ph.D. is a great resource that will be trained and engaged as part of this project to use the annotation tool being developed to collate, curate, manage and visualize this scientific information. This project is funded by Department of Biotechnology (DBT), Government of India as a collaboration between Persistent Systems, NCCS and IISER, Pune.\"\n"
      ],
      "metadata": {
        "id": "qKw34tP1gFl5"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1 :TOKENIZATION : Breaking complex data into simple units\n",
        "#Sentence Tokenizer\n",
        "sentences=sent_tokenize(data)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ved4zIgT-B",
        "outputId": "707c79a0-5520-4999-f786-d325886b4c52"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Recent times have witnessed an explosion in the amount of biological data generated.', 'There are millions of research articles with pivotal information on human health and disease, spanning from single molecule resolution to the level of the whole organism.', 'However, this information is scattered in different databases, repositories and in the text of journal articles.', 'This makes the seamless extraction of scientific information an extremely challenging and time-consuming (yet incomplete) process.', 'With 100+ databases and millions of data points (combined) from just human cells/tissue and disease, there is a pressing need to collate this information in such a way that users like academic/industrial/clinical researcher as well as teachers and students can easily access information that is relevant to them from a common and modular platform.', 'Although there are ambitious ongoing efforts like the Recon X, The Virtual Physiological Human, Human Cell Atlas, none of these projects aim to build the map of the whole human body simultaneously comparing both macro(organ/tissue/cell) and micro (molecular interaction networks) level details.', 'Manav-Human Atlas Initiative aims to construct a comprehensive map of the entire human body which will explicitly document macro to micro level information.', 'The project Manav will dramatically accelerate our understanding of the working of the human body and help design better therapeutic targets for treating diseases like cancer, diabetes and more.', 'This project will require understanding, extracting and collating information from millions of scientific papers which would need a massive investment of time, effort and manpower.', 'The large pool of scientifically literate population in India pursuing a bachelors /masters / Ph.D. is a great resource that will be trained and engaged as part of this project to use the annotation tool being developed to collate, curate, manage and visualize this scientific information.', 'This project is funded by Department of Biotechnology (DBT), Government of India as a collaboration between Persistent Systems, NCCS and IISER, Pune.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenize\n",
        "words=word_tokenize(data)"
      ],
      "metadata": {
        "id": "POONNfrggcFp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgH9o-14gzY-",
        "outputId": "6e2eb908-0789-458f-d7d5-574e3ce88f64"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Recent', 'times', 'have', 'witnessed', 'an', 'explosion', 'in', 'the', 'amount', 'of', 'biological', 'data', 'generated', '.', 'There', 'are', 'millions', 'of', 'research', 'articles', 'with', 'pivotal', 'information', 'on', 'human', 'health', 'and', 'disease', ',', 'spanning', 'from', 'single', 'molecule', 'resolution', 'to', 'the', 'level', 'of', 'the', 'whole', 'organism', '.', 'However', ',', 'this', 'information', 'is', 'scattered', 'in', 'different', 'databases', ',', 'repositories', 'and', 'in', 'the', 'text', 'of', 'journal', 'articles', '.', 'This', 'makes', 'the', 'seamless', 'extraction', 'of', 'scientific', 'information', 'an', 'extremely', 'challenging', 'and', 'time-consuming', '(', 'yet', 'incomplete', ')', 'process', '.', 'With', '100+', 'databases', 'and', 'millions', 'of', 'data', 'points', '(', 'combined', ')', 'from', 'just', 'human', 'cells/tissue', 'and', 'disease', ',', 'there', 'is', 'a', 'pressing', 'need', 'to', 'collate', 'this', 'information', 'in', 'such', 'a', 'way', 'that', 'users', 'like', 'academic/industrial/clinical', 'researcher', 'as', 'well', 'as', 'teachers', 'and', 'students', 'can', 'easily', 'access', 'information', 'that', 'is', 'relevant', 'to', 'them', 'from', 'a', 'common', 'and', 'modular', 'platform', '.', 'Although', 'there', 'are', 'ambitious', 'ongoing', 'efforts', 'like', 'the', 'Recon', 'X', ',', 'The', 'Virtual', 'Physiological', 'Human', ',', 'Human', 'Cell', 'Atlas', ',', 'none', 'of', 'these', 'projects', 'aim', 'to', 'build', 'the', 'map', 'of', 'the', 'whole', 'human', 'body', 'simultaneously', 'comparing', 'both', 'macro', '(', 'organ/tissue/cell', ')', 'and', 'micro', '(', 'molecular', 'interaction', 'networks', ')', 'level', 'details', '.', 'Manav-Human', 'Atlas', 'Initiative', 'aims', 'to', 'construct', 'a', 'comprehensive', 'map', 'of', 'the', 'entire', 'human', 'body', 'which', 'will', 'explicitly', 'document', 'macro', 'to', 'micro', 'level', 'information', '.', 'The', 'project', 'Manav', 'will', 'dramatically', 'accelerate', 'our', 'understanding', 'of', 'the', 'working', 'of', 'the', 'human', 'body', 'and', 'help', 'design', 'better', 'therapeutic', 'targets', 'for', 'treating', 'diseases', 'like', 'cancer', ',', 'diabetes', 'and', 'more', '.', 'This', 'project', 'will', 'require', 'understanding', ',', 'extracting', 'and', 'collating', 'information', 'from', 'millions', 'of', 'scientific', 'papers', 'which', 'would', 'need', 'a', 'massive', 'investment', 'of', 'time', ',', 'effort', 'and', 'manpower', '.', 'The', 'large', 'pool', 'of', 'scientifically', 'literate', 'population', 'in', 'India', 'pursuing', 'a', 'bachelors', '/masters', '/', 'Ph.D.', 'is', 'a', 'great', 'resource', 'that', 'will', 'be', 'trained', 'and', 'engaged', 'as', 'part', 'of', 'this', 'project', 'to', 'use', 'the', 'annotation', 'tool', 'being', 'developed', 'to', 'collate', ',', 'curate', ',', 'manage', 'and', 'visualize', 'this', 'scientific', 'information', '.', 'This', 'project', 'is', 'funded', 'by', 'Department', 'of', 'Biotechnology', '(', 'DBT', ')', ',', 'Government', 'of', 'India', 'as', 'a', 'collaboration', 'between', 'Persistent', 'Systems', ',', 'NCCS', 'and', 'IISER', ',', 'Pune', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stopwrods\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I28dHpfdg75s",
        "outputId": "96007e50-a8a1-4523-b99b-53514c6132f4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud0dG0Wzg8ar",
        "outputId": "beb2788d-6a58-41c2-e243-83892d073e62"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import *"
      ],
      "metadata": {
        "id": "4PZNS_6Bg8er"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *"
      ],
      "metadata": {
        "id": "XhNNeVIfkKn5"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "porter stemmer"
      ],
      "metadata": {
        "id": "I1Lk5dpYkKsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stem=PorterStemmer()"
      ],
      "metadata": {
        "id": "QcKgbr4Kg8in"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
        "          'died', 'agreed', 'owned', 'humbled', 'sized',\n",
        "         'meeting', 'stating', 'siezing', 'itemization',\n",
        "          'sensational', 'traditional', 'reference', 'colonizer',\n",
        "         'plotted']"
      ],
      "metadata": {
        "id": "OT7Cd4Nug8nF"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "singles=[stem.stem(i) for i in plurals]"
      ],
      "metadata": {
        "id": "s6hGKTUZmALp"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "singles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WQAy1JAmAQc",
        "outputId": "414146ea-fd01-4b87-d891-fc01e31547fe"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['caress',\n",
              " 'fli',\n",
              " 'die',\n",
              " 'mule',\n",
              " 'deni',\n",
              " 'die',\n",
              " 'agre',\n",
              " 'own',\n",
              " 'humbl',\n",
              " 'size',\n",
              " 'meet',\n",
              " 'state',\n",
              " 'siez',\n",
              " 'item',\n",
              " 'sensat',\n",
              " 'tradit',\n",
              " 'refer',\n",
              " 'colon',\n",
              " 'plot']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(singles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4pGdTyDmmAU9",
        "outputId": "aa7019a9-e5ce-4d2c-d67c-0a760ad8189d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'caress fli die mule deni die agre own humbl size meet state siez item sensat tradit refer colon plot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "N-MhbDOymAa1"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb=SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "XycGDfMcq1Zu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS5THSTMq1d2",
        "outputId": "e4d4e741-87eb-45d5-b9ef-1e7ceeabbfa7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.stem.snowball.SnowballStemmer at 0x7f5c730dfa10>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sb.languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A0Wf7zUrLkp",
        "outputId": "0ac418b9-50d0-474b-eb05-3f766918b5ed"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sb.stem('running')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4bOvCZ6UrVHy",
        "outputId": "abbad0a6-594e-459c-9a0d-fd7bd28f2100"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sb1=SnowballStemmer('english',ignore_stopwords=True)"
      ],
      "metadata": {
        "id": "_jX9AwHXrVMK"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb1.stem('having')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rWscJwVQrjfv",
        "outputId": "225303f4-57a9-40c8-c012-929b445cc593"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'having'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sb.stem('having')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Su6g2V4rjkV",
        "outputId": "0da367cb-7d9b-4266-b1c6-f1ccaecece29"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GQetSsarz8u",
        "outputId": "130e185f-953e-4c50-cef4-762643518816"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Recent times have witnessed an explosion in the amount of biological data generated.',\n",
              " 'There are millions of research articles with pivotal information on human health and disease, spanning from single molecule resolution to the level of the whole organism.',\n",
              " 'However, this information is scattered in different databases, repositories and in the text of journal articles.',\n",
              " 'This makes the seamless extraction of scientific information an extremely challenging and time-consuming (yet incomplete) process.',\n",
              " 'With 100+ databases and millions of data points (combined) from just human cells/tissue and disease, there is a pressing need to collate this information in such a way that users like academic/industrial/clinical researcher as well as teachers and students can easily access information that is relevant to them from a common and modular platform.',\n",
              " 'Although there are ambitious ongoing efforts like the Recon X, The Virtual Physiological Human, Human Cell Atlas, none of these projects aim to build the map of the whole human body simultaneously comparing both macro(organ/tissue/cell) and micro (molecular interaction networks) level details.',\n",
              " 'Manav-Human Atlas Initiative aims to construct a comprehensive map of the entire human body which will explicitly document macro to micro level information.',\n",
              " 'The project Manav will dramatically accelerate our understanding of the working of the human body and help design better therapeutic targets for treating diseases like cancer, diabetes and more.',\n",
              " 'This project will require understanding, extracting and collating information from millions of scientific papers which would need a massive investment of time, effort and manpower.',\n",
              " 'The large pool of scientifically literate population in India pursuing a bachelors /masters / Ph.D. is a great resource that will be trained and engaged as part of this project to use the annotation tool being developed to collate, curate, manage and visualize this scientific information.',\n",
              " 'This project is funded by Department of Biotechnology (DBT), Government of India as a collaboration between Persistent Systems, NCCS and IISER, Pune.']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words=word_tokenize(sentences[i])\n",
        "  w1=[sb.stem(i) for i in words if i not in stopwords.words('english')]\n",
        "  w2= ' '.join(w1)"
      ],
      "metadata": {
        "id": "uWlan9hmr0A7"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "njjeg_mNrLqs",
        "outputId": "47ef679e-0337-40da-ec55-b1da0641b19f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this project fund depart biotechnolog ( dbt ) , govern india collabor persist system , nccs iiser , pune .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIfRYENAtOPi",
        "outputId": "c5577948-fe24-4388-fb1e-51808af026af"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'project',\n",
              " 'is',\n",
              " 'funded',\n",
              " 'by',\n",
              " 'Department',\n",
              " 'of',\n",
              " 'Biotechnology',\n",
              " '(',\n",
              " 'DBT',\n",
              " ')',\n",
              " ',',\n",
              " 'Government',\n",
              " 'of',\n",
              " 'India',\n",
              " 'as',\n",
              " 'a',\n",
              " 'collaboration',\n",
              " 'between',\n",
              " 'Persistent',\n",
              " 'Systems',\n",
              " ',',\n",
              " 'NCCS',\n",
              " 'and',\n",
              " 'IISER',\n",
              " ',',\n",
              " 'Pune',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LEMMATIZATION\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rIwEu2ZtUv_",
        "outputId": "bba05808-6764-4a61-d1b3-04188343c213"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lem=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "7nU7aFLLyKbU"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words=word_tokenize(sentences[i])\n",
        "  w3=[lem.lemmatize(i.lower()) for i in words if i not in stopwords.words('english')]\n",
        "  w4=' '.join(w3)"
      ],
      "metadata": {
        "id": "gBEkIuryyM9c"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GOjDw5dxyi3J",
        "outputId": "ae43ee57-204a-44d3-8b3e-62f1bec867a7"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this project funded department biotechnology ( dbt ) , government india collaboration persistent system , nccs iiser , pune .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#POS (Part-Of-Speech) Tagging\n",
        "POS (Parts of Speech) tell us about grammatical information of words of the sentence by assigning specific token (Determiner, noun, adjective , adverb ,verb,Personal Pronoun etc.) as tag (DT,NN ,JJ,RB,VB,PRP etc) to each words.\n",
        "\n",
        "Word can have more than one POS depending upon context where it is used. we can use POS tags as statistical NLP tasks it distinguishes sense of word which is very helpful in text realization and infer semantic information from gives text for sentiment analysis."
      ],
      "metadata": {
        "id": "-V0a_Cmry0c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33E9QWMsy5KW",
        "outputId": "12eec0ef-e373-4282-8128-920eff003c08"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'project',\n",
              " 'funded',\n",
              " 'department',\n",
              " 'biotechnology',\n",
              " '(',\n",
              " 'dbt',\n",
              " ')',\n",
              " ',',\n",
              " 'government',\n",
              " 'india',\n",
              " 'collaboration',\n",
              " 'persistent',\n",
              " 'system',\n",
              " ',',\n",
              " 'nccs',\n",
              " 'iiser',\n",
              " ',',\n",
              " 'pune',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MV56f5Lqy5S4",
        "outputId": "58d77c73-b8b9-42bd-b52c-d965b60a835d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this project funded department biotechnology ( dbt ) , government india collaboration persistent system , nccs iiser , pune .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUIm1Vq2zyq7",
        "outputId": "9cc69e28-4869-4d91-a13b-dfccf08e5ae4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"The pink sweater fit her perfectly\"\n",
        "d1=word_tokenize(data)\n",
        "for word in d1:\n",
        "  print(nltk.pos_tag([word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6IKHckuzg_W",
        "outputId": "62bd21ab-e32b-4bbf-ecff-1870b0724b03"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT')]\n",
            "[('pink', 'NN')]\n",
            "[('sweater', 'NN')]\n",
            "[('fit', 'NN')]\n",
            "[('her', 'PRP$')]\n",
            "[('perfectly', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "2eYY2JjLzqYx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow=CountVectorizer()"
      ],
      "metadata": {
        "id": "aLcTC1uw0EZ7"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKFn6KMt0EgV",
        "outputId": "99e19b50-a91e-4d0c-8c3b-4d6121de7a6a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Recent times have witnessed an explosion in the amount of biological data generated.',\n",
              " 'There are millions of research articles with pivotal information on human health and disease, spanning from single molecule resolution to the level of the whole organism.',\n",
              " 'However, this information is scattered in different databases, repositories and in the text of journal articles.',\n",
              " 'This makes the seamless extraction of scientific information an extremely challenging and time-consuming (yet incomplete) process.',\n",
              " 'With 100+ databases and millions of data points (combined) from just human cells/tissue and disease, there is a pressing need to collate this information in such a way that users like academic/industrial/clinical researcher as well as teachers and students can easily access information that is relevant to them from a common and modular platform.',\n",
              " 'Although there are ambitious ongoing efforts like the Recon X, The Virtual Physiological Human, Human Cell Atlas, none of these projects aim to build the map of the whole human body simultaneously comparing both macro(organ/tissue/cell) and micro (molecular interaction networks) level details.',\n",
              " 'Manav-Human Atlas Initiative aims to construct a comprehensive map of the entire human body which will explicitly document macro to micro level information.',\n",
              " 'The project Manav will dramatically accelerate our understanding of the working of the human body and help design better therapeutic targets for treating diseases like cancer, diabetes and more.',\n",
              " 'This project will require understanding, extracting and collating information from millions of scientific papers which would need a massive investment of time, effort and manpower.',\n",
              " 'The large pool of scientifically literate population in India pursuing a bachelors /masters / Ph.D. is a great resource that will be trained and engaged as part of this project to use the annotation tool being developed to collate, curate, manage and visualize this scientific information.',\n",
              " 'This project is funded by Department of Biotechnology (DBT), Government of India as a collaboration between Persistent Systems, NCCS and IISER, Pune.']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=bow.fit_transform(sentences).toarray()"
      ],
      "metadata": {
        "id": "bBlWvNNQC1WQ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEHr3w0VC29p",
        "outputId": "c50161a9-b8cb-45de-bd3b-46c345fee924"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF\n",
        "TF-IDF stands for Term Frequency-Inverse Document Frequency\n",
        "\n",
        "“Term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.”\n",
        "\n",
        "Term Frequency: is a scoring of the frequency of the word in the current document.\n",
        "Inverse Document Frequency: is a scoring of how rare the word is across documents.MM"
      ],
      "metadata": {
        "id": "jMickt90C3DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "_pVqI0f8DQwP"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=TfidfVectorizer()"
      ],
      "metadata": {
        "id": "7ncvF8ujDQy-"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1=tfidf.fit_transform(sentences).toarray()"
      ],
      "metadata": {
        "id": "9u5D2KMTDQ2k"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmkSmUk1Dldd",
        "outputId": "88319142-918a-4801-fe28-ed2563637969"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.24762571,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u8rw8ahoDmGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}